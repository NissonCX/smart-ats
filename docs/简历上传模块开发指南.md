# 简历上传模块开发指南

> 本模块是 SmartATS 的核心功能之一，涉及文件存储、异步处理、分布式锁等多个技术点
> 预计学习时间：1-2 周
> 难度等级：⭐⭐⭐⭐（四星）

> **⚠️ 重要提示**：本项目的服务配置（端口、密码等）请参考 `docs/环境信息.md`
>
> - MySQL 端口：3307（不是默认的 3306）
> - MinIO 凭证：admin/admin123456（不是 minioadmin）
> - RabbitMQ 凭证：admin/admin123（不是 guest）
> - Redis 密码：redis123（不是空）

---

## 目录

1. [模块概览](#1-模块概览)
2. [技术方案选型](#2-技术方案选型)
3. [开发前准备](#3-开发前准备)
4. [第一阶段：MinIO 配置与文件服务](#4-第一阶段minio-配置与文件服务)
5. [第二阶段：文件上传接口](#5-第二阶段文件上传接口)
6. [第三阶段：RabbitMQ 集成](#6-第三阶段rabbitmq-集成)
7. [第四阶段：异步解析消费者](#7-第四阶段异步解析消费者)
8. [第五阶段：任务状态跟踪](#8-第五阶段任务状态跟踪)
9. [完整代码示例](#9-完整代码示例)
10. [测试验收标准](#10-测试验收标准)
11. [常见问题排查](#11-常见问题排查)

---

## 1. 模块概览

### 1.1 业务流程

```
用户上传简历
    ↓
校验文件（类型、大小）
    ↓
计算 MD5
    ↓
检查去重（Redis）
    ↓
已存在？ → YES → 返回已有简历ID
    ↓ NO
存储文件（MinIO）
    ↓
保存数据库记录（resumes 表）
    ↓
发送 MQ 消息
    ↓
返回 taskId
    ↓
前端轮询任务状态
    ↓
后台异步解析（MQ 消费者）
    ↓
解析完成，更新 candidates 表
```

### 1.2 核心技术点

| 技术点 | 用途 | 难度 |
|--------|------|------|
| MinIO | 对象存储，兼容 S3 API | ⭐⭐ |
| MD5 计算 | 文件去重 | ⭐ |
| Redis 缓存 | 去重标记、任务状态 | ⭐⭐ |
| RabbitMQ | 异步解耦 | ⭐⭐⭐ |
| 分布式锁 | 防止重复解析 | ⭐⭐⭐ |

### 1.3 开发顺序（⚠️ 必须按此顺序）

```
第 1 步：配置 MinIO ⭐ 最重要！
  └─ 启动 MinIO 服务
  └─ 配置 MinIO 客户端
  └─ 测试文件上传/下载

第 2 步：实现文件服务层
  └─ FileStorageService 接口
  └─ MinIOFileStorageService 实现
  └─ 单元测试

第 3 步：实现上传接口（同步部分）
  └─ ResumeController.upload()
  └─ MD5 计算
  └─ 去重检查
  └─ 文件存储
  └─ 数据库记录

第 4 步：集成 RabbitMQ
  └─ 配置 RabbitMQ
  └─ 创建队列和交换机
  └─ 实现消息发送

第 5 步：实现 MQ 消费者（异步部分）
  └─ ResumeParseConsumer
  └─ 分布式锁
  └─ AI 解析（暂用 mock）
  └─ 更新任务状态

第 6 步：实现任务状态查询接口
  └─ ResumeController.getTaskStatus()
  └─ Redis 状态读取
```

---

## 2. 技术方案选型

### 2.1 为什么选择 MinIO？

| 方案 | 优点 | 缺点 | 推荐指数 |
|------|------|------|----------|
| **MinIO** | 免费、兼容 S3、自托管 | 需要自己运维 | ⭐⭐⭐⭐⭐ |
| 阿里云 OSS | 稳定、免运维 | 需要付费 | ⭐⭐⭐⭐ |
| 本地文件系统 | 简单 | 扩展性差、不支持分布式 | ⭐⭐ |
| 数据库 BLOB | 简单 | 性能差、影响数据库 | ⭐ |

**推荐方案**：开发阶段使用 MinIO，生产环境可无缝切换到阿里云 OSS

### 2.2 MinIO vs 阿里云 OSS

```
MinIO 开发 → 生产演进路径：

本地开发（localhost:9000）
    ↓
测试环境（云服务器 MinIO）
    ↓
生产环境（二选一）
  ├─ 小规模：继续 MinIO（省钱）
  └─ 大规模：阿里云 OSS（稳定）
```

**关键优势**：MinIO 完全兼容 S3 API，代码写好后，切换到 OSS 只需改配置！

---

## 3. 开发前准备

### 3.1 环境检查清单

在开始之前，确保以下环境已就绪：

- [ ] MinIO 服务运行中
- [ ] MySQL 数据库已创建 resumes 表
- [ ] RabbitMQ 服务运行中
- [ ] Redis 服务运行中
- [ ] 项目已添加必要依赖

### 3.2 启动 MinIO 服务

**重要说明**：本项目使用自定义 MinIO 凭据（见 `docs/环境信息.md`）

**使用 Docker 启动（推荐）**：

```bash
# 创建 docker-compose.yml
version: '3.8'
services:
  minio:
    image: minio/minio:latest
    container_name: smartats-minio
    ports:
      - "9000:9000"  # API 端口
      - "9001:9001"  # 控制台端口
    environment:
      MINIO_ROOT_USER: admin              # ⚠️ 本项目使用 admin
      MINIO_ROOT_PASSWORD: admin123456    # ⚠️ 本项目使用 admin123456
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data

volumes:
  minio_data:
```

**启动命令**：

```bash
docker-compose up -d minio
```

**验证启动**：

```bash
# 检查容器状态
docker ps | grep minio

# 访问控制台
open http://localhost:9001
# 账号：admin / admin123456
```

### 3.3 创建 Bucket

1. 登录 MinIO 控制台（http://localhost:9001）
2. 点击左侧 "Buckets"
3. 点击 "Create Bucket"
4. 命名为 `smartats-resumes`
5. Access Policy 设置为 `Public`（开发环境）

或者通过 API 创建（推荐代码实现，稍后讲解）

### 3.4 添加 Maven 依赖

在 `pom.xml` 中添加：

```xml
<!-- MinIO 客户端 -->
<dependency>
    <groupId>io.minio</groupId>
    <artifactId>minio</artifactId>
    <version>8.5.7</version>
</dependency>

<!-- Apache Commons Codec（用于 MD5 计算） -->
<dependency>
    <groupId>commons-codec</groupId>
    <artifactId>commons-codec</artifactId>
</dependency>

<!-- RabbitMQ -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-amqp</artifactId>
</dependency>

<!-- 如果需要手动上传 Multipart，确保已有此依赖 -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-web</artifactId>
</dependency>
```

### 3.5 配置文件

在 `application.yml` 中添加配置：

```yaml
# MinIO 配置
minio:
  endpoint: http://localhost:9000
  access-key: minioadmin
  secret-key: minioadmin
  bucket-name: smartats-resumes
  connect-timeout: 10000  # 10秒
  write-timeout: 60000     # 60秒
  read-timeout: 10000      # 10秒

# 文件上传限制
spring:
  servlet:
    multipart:
      enabled: true
      max-file-size: 10MB       # 单个文件最大 10MB
      max-request-size: 50MB    # 请求最大 50MB
      file-size-threshold: 2MB  # 超过 2MB 才写入磁盘

# RabbitMQ 配置
spring:
  rabbitmq:
    host: localhost
    port: 5672
    username: guest
    password: guest
    virtual-host: /
    listener:
      simple:
        acknowledge-mode: manual  # 手动确认消息
        prefetch: 1               # 限流，每次只处理 1 条
        retry:
          enabled: true
          max-attempts: 3
          initial-interval: 2000
```

---

## 4. 第一阶段：MinIO 配置与文件服务

### 4.1 理解 MinIO 核心概念

**MinIO 是对象存储，核心概念**：

| 概念 | 说明 | 类比 |
|------|------|------|
| Bucket | 存储桶，文件的组织单位 | 文件夹 |
| Object | 对象，实际存储的文件 | 文件 |
| Prefix | 前缀，对象的路径 | 子文件夹 |
| Presigned URL | 预签名 URL，临时访问链接 | 临时下载链接 |

### 4.2 创建 MinIO 配置类

**文件位置**：`src/main/java/com/smartats/config/MinioConfig.java`

```java
package com.smartats.config;

import io.minio.MinioClient;
import lombok.Data;
import org.springframework.boot.context.properties.ConfigurationProperties;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Data
@Configuration
@ConfigurationProperties(prefix = "minio")
public class MinioConfig {

    private String endpoint;
    private String accessKey;
    private String secretKey;
    private String bucketName;
    private Integer connectTimeout;
    private Integer writeTimeout;
    private Integer readTimeout;

    @Bean
    public MinioClient minioClient() {
        return MinioClient.builder()
                .endpoint(endpoint)
                .credentials(accessKey, secretKey)
                .build();
    }
}
```

**关键点说明**：
- `@ConfigurationProperties`：自动从配置文件读取 minio.* 配置
- `MinioClient`：MinIO 的 Java 客户端，线程安全，可以全局单例

### 4.3 定义文件存储服务接口

**文件位置**：`src/main/java/com/smartats/infrastructure/storage/FileStorageService.java`

```java
package com.smartats.infrastructure.storage;

import org.springframework.web.multipart.MultipartFile;

import java.io.InputStream;

/**
 * 文件存储服务接口
 * 设计原则：面向接口编程，方便后续切换到阿里云 OSS
 */
public interface FileStorageService {

    /**
     * 上传文件
     *
     * @param file       文件
     * @param objectName 对象名（文件路径）
     * @return 文件访问路径
     */
    String uploadFile(MultipartFile file, String objectName);

    /**
     * 上传文件流
     *
     * @param inputStream 文件流
     * @param objectName  对象名
     * @param size        文件大小
     * @param contentType 文件类型
     * @return 文件访问路径
     */
    String uploadFile(InputStream inputStream, String objectName, long size, String contentType);

    /**
     * 删除文件
     *
     * @param objectName 对象名
     */
    void deleteFile(String objectName);

    /**
     * 获取文件访问 URL
     *
     * @param objectName 对象名
     * @return 访问 URL
     */
    String getFileUrl(String objectName);

    /**
     * 生成预签名 URL（临时访问链接）
     *
     * @param objectName 对象名
     * @param expires    过期时间（秒）
     * @return 预签名 URL
     */
    String getPresignedUrl(String objectName, int expires);

    /**
     * 检查文件是否存在
     *
     * @param objectName 对象名
     * @return 是否存在
     */
    boolean fileExists(String objectName);

    /**
     * 确保 Bucket 存在
     */
    void ensureBucketExists();
}
```

**设计亮点**：
1. **面向接口编程**：后续切换到阿里云 OSS 只需新增实现类
2. **方法完整**：覆盖上传、删除、查询、预签名 URL 等常用操作
3. **注释清晰**：每个方法都有明确的用途说明

### 4.4 实现 MinIO 文件存储服务

**文件位置**：`src/main/java/com/smartats/infrastructure/storage/MinioFileStorageService.java`

```java
package com.smartats.infrastructure.storage;

import io.minio.*;
import io.minio.http.Method;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Service;
import org.springframework.web.multipart.MultipartFile;

import java.io.InputStream;
import java.util.concurrent.TimeUnit;

@Slf4j
@Service
@RequiredArgsConstructor
public class MinioFileStorageService implements FileStorageService {

    private final MinioClient minioClient;

    @Value("${minio.bucket-name}")
    private String bucketName;

    @Value("${minio.endpoint}")
    private String endpoint;

    @Override
    public String uploadFile(MultipartFile file, String objectName) {
        try {
            InputStream inputStream = file.getInputStream();
            long size = file.getSize();
            String contentType = file.getContentType();

            return uploadFile(inputStream, objectName, size, contentType);
        } catch (Exception e) {
            log.error("上传文件失败: objectName={}", objectName, e);
            throw new RuntimeException("文件上传失败", e);
        }
    }

    @Override
    public String uploadFile(InputStream inputStream, String objectName, long size, String contentType) {
        try {
            // 确保 Bucket 存在
            ensureBucketExists();

            // 上传文件
            PutObjectArgs putObjectArgs = PutObjectArgs.builder()
                    .bucket(bucketName)
                    .object(objectName)
                    .stream(inputStream, size, -1)  // -1 表示不使用 part 上传
                    .contentType(contentType)
                    .build();

            minioClient.putObject(putObjectArgs);

            log.info("文件上传成功: bucket={}, object={}", bucketName, objectName);

            // 返回访问路径
            return getFileUrl(objectName);

        } catch (Exception e) {
            log.error("上传文件流失败: objectName={}", objectName, e);
            throw new RuntimeException("文件上传失败", e);
        }
    }

    @Override
    public void deleteFile(String objectName) {
        try {
            RemoveObjectArgs removeObjectArgs = RemoveObjectArgs.builder()
                    .bucket(bucketName)
                    .object(objectName)
                    .build();

            minioClient.removeObject(removeObjectArgs);

            log.info("文件删除成功: objectName={}", objectName);

        } catch (Exception e) {
            log.error("删除文件失败: objectName={}", objectName, e);
            throw new RuntimeException("文件删除失败", e);
        }
    }

    @Override
    public String getFileUrl(String objectName) {
        // 公共访问 URL（需要 Bucket 设置为 Public）
        return String.format("%s/%s/%s", endpoint, bucketName, objectName);
    }

    @Override
    public String getPresignedUrl(String objectName, int expires) {
        try {
            GetPresignedObjectUrlArgs args = GetPresignedObjectUrlArgs.builder()
                    .method(Method.GET)
                    .bucket(bucketName)
                    .object(objectName)
                    .expiry(expires, TimeUnit.SECONDS)
                    .build();

            return minioClient.getPresignedObjectUrl(args);

        } catch (Exception e) {
            log.error("生成预签名URL失败: objectName={}", objectName, e);
            throw new RuntimeException("生成预签名URL失败", e);
        }
    }

    @Override
    public boolean fileExists(String objectName) {
        try {
            StatObjectArgs args = StatObjectArgs.builder()
                    .bucket(bucketName)
                    .object(objectName)
                    .build();

            minioClient.statObject(args);
            return true;

        } catch (Exception e) {
            return false;
        }
    }

    @Override
    public void ensureBucketExists() {
        try {
            // 检查 Bucket 是否存在
            boolean found = minioClient.bucketExists(
                    BucketExistsArgs.builder()
                            .bucket(bucketName)
                            .build()
            );

            if (!found) {
                // 创建 Bucket
                minioClient.makeBucket(
                        MakeBucketArgs.builder()
                                .bucket(bucketName)
                                .build()
                );
                log.info("创建 Bucket 成功: {}", bucketName);

                // 设置 Bucket 为公共读取（开发环境）
                // 生产环境建议使用预签名 URL
                String config = "{\"Version\":\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Principal\":{\"AWS\":[\"*\"]},\"Action\":[\"s3:GetObject\"],\"Resource\":[\"arn:aws:s3:::" + bucketName + "/*\"]}]}";
                // 注意：这里需要根据实际 MinIO 版本调整配置方式
            }

        } catch (Exception e) {
            log.error("检查/创建 Bucket 失败: bucket={}", bucketName, e);
            throw new RuntimeException("Bucket 初始化失败", e);
        }
    }
}
```

**代码详解**：

1. **文件上传**：
   - 先确保 Bucket 存在
   - 使用 `PutObjectArgs` 构建上传参数
   - `stream(inputStream, size, -1)`：-1 表示不使用分片上传（适合小文件）

2. **文件删除**：
   - 使用 `RemoveObjectArgs` 构建删除参数
   - 删除是永久操作，谨慎使用

3. **文件访问**：
   - `getFileUrl()`：返回公共访问 URL（Bucket 需设置为 Public）
   - `getPresignedUrl()`：返回临时访问链接（推荐生产环境使用）

4. **文件检查**：
   - `fileExists()`：使用 `statObject()` 检查文件是否存在
   - 捕获异常，不存在时返回 false

### 4.5 单元测试

**文件位置**：`src/test/java/com/smartats/infrastructure/storage/MinioFileStorageServiceTest.java`

```java
package com.smartats.infrastructure.storage;

import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.mock.web.MockMultipartFile;
import org.springframework.test.context.ActiveProfiles;

import java.io.FileInputStream;
import java.nio.charset.StandardCharsets;

import static org.junit.jupiter.api.Assertions.*;

@SpringBootTest
@ActiveProfiles("test")
class MinioFileStorageServiceTest {

    @Autowired
    private FileStorageService fileStorageService;

    @Test
    void testEnsureBucketExists() {
        // 应该不抛异常
        assertDoesNotThrow(() -> fileStorageService.ensureBucketExists());
    }

    @Test
    void testUploadAndDeleteFile() throws Exception {
        // 准备测试文件
        String content = "Hello, MinIO!";
        MockMultipartFile file = new MockMultipartFile(
                "file",
                "test.txt",
                "text/plain",
                content.getBytes(StandardCharsets.UTF_8)
        );

        String objectName = "test/" + System.currentTimeMillis() + "/test.txt";

        // 测试上传
        String url = fileStorageService.uploadFile(file, objectName);
        assertNotNull(url);
        assertTrue(url.contains(objectName));

        // 测试文件存在
        assertTrue(fileStorageService.fileExists(objectName));

        // 测试获取 URL
        String fileUrl = fileStorageService.getFileUrl(objectName);
        assertNotNull(fileUrl);

        // 测试删除
        assertDoesNotThrow(() -> fileStorageService.deleteFile(objectName));

        // 测试文件不存在
        assertFalse(fileStorageService.fileExists(objectName));
    }

    @Test
    void testGetPresignedUrl() {
        String objectName = "test/presigned.txt";

        String url = fileStorageService.getPresignedUrl(objectName, 3600);
        assertNotNull(url);
        assertTrue(url.contains("X-Amz-Expires"));
    }
}
```

**运行测试**：

```bash
# 确保 MinIO 和应用都已启动
mvn test -Dtest=MinioFileStorageServiceTest
```

**验收标准**：
- ✅ 所有测试通过
- ✅ 能在 MinIO 控制台看到上传的文件
- ✅ 能通过浏览器访问文件 URL

---

## 5. 第二阶段：文件上传接口

### 5.1 创建数据表

**文件位置**：`src/main/resources/sql/resumes.sql`

```sql
USE smartats;

-- 简历表
CREATE TABLE IF NOT EXISTS `resumes` (
    `id` BIGINT PRIMARY KEY AUTO_INCREMENT COMMENT '简历ID',
    `user_id` BIGINT NOT NULL COMMENT '用户ID',
    `file_name` VARCHAR(255) NOT NULL COMMENT '文件名',
    `file_path` VARCHAR(500) NOT NULL COMMENT '文件路径（MinIO objectName）',
    `file_url` VARCHAR(500) NOT NULL COMMENT '文件访问URL',
    `file_size` BIGINT NOT NULL COMMENT '文件大小（字节）',
    `file_hash` VARCHAR(32) NOT NULL UNIQUE COMMENT '文件MD5哈希（去重）',
    `file_type` VARCHAR(50) NOT NULL COMMENT '文件类型（application/pdf等）',
    `status` ENUM('PARSING', 'COMPLETED', 'FAILED') NOT NULL DEFAULT 'PARSING' COMMENT '解析状态',
    `error_message` TEXT COMMENT '错误信息（失败时记录）',
    `created_at` DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
    `updated_at` DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

    INDEX `idx_user_id` (`user_id`),
    INDEX `idx_file_hash` (`file_hash`),
    INDEX `idx_status` (`status`),
    INDEX `idx_created_at` (`created_at`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='简历表';
```

**字段说明**：

| 字段 | 类型 | 说明 |
|------|------|------|
| `file_hash` | VARCHAR(32) | MD5 哈希，**唯一索引**，用于去重 |
| `file_path` | VARCHAR(500) | MinIO 对象名，例如 `resumes/2026/02/19/abc.pdf` |
| `file_url` | VARCHAR(500) | 完整访问 URL，方便前端直接使用 |
| `status` | ENUM | 解析状态：PARSING（解析中）、COMPLETED（完成）、FAILED（失败） |

### 5.2 创建实体类

**文件位置**：`src/main/java/com/smartats/module/resume/entity/Resume.java`

```java
package com.smartats.module.resume.entity;

import com.baomidou.mybatisplus.annotation.*;
import lombok.Data;

import java.time.LocalDateTime;

@Data
@TableName("resumes")
public class Resume {

    @TableId(type = IdType.AUTO)
    private Long id;

    private Long userId;
    private String fileName;
    private String filePath;
    private String fileUrl;
    private Long fileSize;
    private String fileHash;
    private String fileType;
    private String status;  // PARSING, COMPLETED, FAILED
    private String errorMessage;

    @TableField(fill = FieldFill.INSERT)
    private LocalDateTime createdAt;

    @TableField(fill = FieldFill.INSERT_UPDATE)
    private LocalDateTime updatedAt;
}
```

### 5.3 创建 Mapper

**文件位置**：`src/main/java/com/smartats/module/resume/mapper/ResumeMapper.java`

```java
package com.smartats.module.resume.mapper;

import com.baomidou.mybatisplus.core.mapper.BaseMapper;
import com.smartats.module.resume.entity.Resume;
import org.apache.ibatis.annotations.Mapper;

@Mapper
public interface ResumeMapper extends BaseMapper<Resume> {
}
```

### 5.4 创建 DTO

**文件位置**：`src/main/java/com/smartats/module/resume/dto/ResumeUploadResponse.java`

```java
package com.smartats.module.resume.dto;

import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;

@Data
@NoArgsConstructor
@AllArgsConstructor
public class ResumeUploadResponse {

    /**
     * 任务ID（前端用于轮询状态）
     */
    private String taskId;

    /**
     * 简历ID
     */
    private Long resumeId;

    /**
     * 文件是否已存在（去重）
     */
    private Boolean duplicated;

    /**
     * 提示信息
     */
    private String message;
}
```

**文件位置**：`src/main/java/com/smartats/module/resume/dto/TaskStatusResponse.java`

```java
package com.smartats.module.resume.dto;

import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;

@Data
@NoArgsConstructor
@AllArgsConstructor
public class TaskStatusResponse {

    /**
     * 任务状态
     */
    private String status;

    /**
     * 简历ID（解析完成后有值）
     */
    private Long resumeId;

    /**
     * 候选人ID（解析完成后有值）
     */
    private Long candidateId;

    /**
     * 错误信息（失败时有值）
     */
    private String errorMessage;

    /**
     * 进度百分比（0-100）
     */
    private Integer progress;
}
```

### 5.5 创建 Service

**文件位置**：`src/main/java/com/smartats/module/resume/service/ResumeService.java`

```java
package com.smartats.module.resume.service;

import com.baomidou.mybatisplus.core.conditions.query.LambdaQueryWrapper;
import com.smartats.module.resume.dto.ResumeUploadResponse;
import com.smartats.module.resume.dto.TaskStatusResponse;
import com.smartats.module.resume.entity.Resume;
import com.smartats.module.resume.mapper.ResumeMapper;
import com.smartats.infrastructure.storage.FileStorageService;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.apache.commons.codec.digest.DigestUtils;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;
import org.springframework.web.multipart.MultipartFile;

import java.io.IOException;
import java.time.LocalDateTime;
import java.time.format.DateTimeFormatter;
import java.util.UUID;
import java.util.concurrent.TimeUnit;

@Slf4j
@Service
@RequiredArgsConstructor
public class ResumeService {

    private final ResumeMapper resumeMapper;
    private final FileStorageService fileStorageService;
    private final RedisTemplate<String, Object> redisTemplate;

    private static final String RESUME_DEDUP_KEY_PREFIX = "dedup:resume:";
    private static final String TASK_STATUS_KEY_PREFIX = "task:resume:";
    private static final long TASK_STATUS_TTL = 24; // 24小时

    /**
     * 上传简历
     */
    @Transactional(rollbackFor = Exception.class)
    public ResumeUploadResponse uploadResume(MultipartFile file, Long userId) {
        // 1. 校验文件
        validateFile(file);

        // 2. 计算 MD5
        String fileHash;
        try {
            fileHash = DigestUtils.md5Hex(file.getInputStream());
        } catch (IOException e) {
            log.error("计算文件MD5失败", e);
            throw new RuntimeException("文件处理失败");
        }

        // 3. 检查去重（Redis + DB）
        Resume existingResume = checkDuplicate(fileHash);
        if (existingResume != null) {
            log.info("文件已存在: hash={}, userId={}", fileHash, userId);
            return new ResumeUploadResponse(
                    existingResume.getId().toString(),
                    existingResume.getId(),
                    true,
                    "文件已存在，直接使用已有简历"
            );
        }

        // 4. 生成文件路径
        String objectName = generateObjectName(fileHash, file.getOriginalFilename());

        // 5. 上传文件到 MinIO
        String fileUrl;
        try {
            fileUrl = fileStorageService.uploadFile(file, objectName);
        } catch (Exception e) {
            log.error("文件上传失败: objectName={}", objectName, e);
            throw new RuntimeException("文件上传失败");
        }

        // 6. 保存数据库记录
        Resume resume = new Resume();
        resume.setUserId(userId);
        resume.setFileName(file.getOriginalFilename());
        resume.setFilePath(objectName);
        resume.setFileUrl(fileUrl);
        resume.setFileSize(file.getSize());
        resume.setFileHash(fileHash);
        resume.setFileType(file.getContentType());
        resume.setStatus("PARSING");
        resume.setCreatedAt(LocalDateTime.now());
        resume.setUpdatedAt(LocalDateTime.now());

        resumeMapper.insert(resume);

        // 7. 写入去重标记（Redis）
        String dedupKey = RESUME_DEDUP_KEY_PREFIX + fileHash;
        redisTemplate.opsForValue().set(dedupKey, resume.getId(), 7, TimeUnit.DAYS);

        // 8. 生成任务ID
        String taskId = UUID.randomUUID().toString();

        // 9. 写入任务状态（Redis）
        TaskStatusResponse taskStatus = new TaskStatusResponse();
        taskStatus.setStatus("QUEUED");
        taskStatus.setProgress(0);

        String taskKey = TASK_STATUS_KEY_PREFIX + taskId;
        redisTemplate.opsForValue().set(taskKey, taskStatus, TASK_STATUS_TTL, TimeUnit.HOURS);

        // 10. 发送 MQ 消息（下一阶段实现）
        // TODO: 发送 MQ 消息到解析队列

        log.info("简历上传成功: resumeId={}, taskId={}, hash={}", resume.getId(), taskId, fileHash);

        return new ResumeUploadResponse(
                taskId,
                resume.getId(),
                false,
                "简历上传成功，正在解析中"
        );
    }

    /**
     * 查询任务状态
     */
    public TaskStatusResponse getTaskStatus(String taskId) {
        String taskKey = TASK_STATUS_KEY_PREFIX + taskId;

        // 1. 先查 Redis
        TaskStatusResponse status = (TaskStatusResponse) redisTemplate.opsForValue().get(taskKey);

        if (status != null) {
            return status;
        }

        // 2. Redis 没有，返回默认状态
        return new TaskStatusResponse("NOT_FOUND", null, null, null, 0);
    }

    /**
     * 校验文件
     */
    private void validateFile(MultipartFile file) {
        if (file == null || file.isEmpty()) {
            throw new RuntimeException("文件不能为空");
        }

        // 校验文件大小（10MB）
        long maxSize = 10 * 1024 * 1024;
        if (file.getSize() > maxSize) {
            throw new RuntimeException("文件大小不能超过 10MB");
        }

        // 校验文件类型
        String contentType = file.getContentType();
        if (contentType == null ||
                (!contentType.equals("application/pdf") &&
                 !contentType.equals("application/vnd.openxmlformats-officedocument.wordprocessingml.document") &&
                 !contentType.equals("application/msword"))) {
            throw new RuntimeException("只支持 PDF 和 Word 格式");
        }
    }

    /**
     * 检查文件是否已存在
     */
    private Resume checkDuplicate(String fileHash) {
        // 1. 先查 Redis 去重标记
        String dedupKey = RESUME_DEDUP_KEY_PREFIX + fileHash;
        Object cachedResumeId = redisTemplate.opsForValue().get(dedupKey);

        if (cachedResumeId != null) {
            Long resumeId = Long.valueOf(cachedResumeId.toString());
            return resumeMapper.selectById(resumeId);
        }

        // 2. Redis 没有，查数据库
        LambdaQueryWrapper<Resume> wrapper = new LambdaQueryWrapper<>();
        wrapper.eq(Resume::getFileHash, fileHash);
        wrapper.last("LIMIT 1");

        Resume resume = resumeMapper.selectOne(wrapper);

        // 3. 如果数据库有，回填 Redis
        if (resume != null) {
            redisTemplate.opsForValue().set(dedupKey, resume.getId(), 7, TimeUnit.DAYS);
        }

        return resume;
    }

    /**
     * 生成对象名（文件路径）
     * 格式：resumes/2026/02/19/{md5前8位}_{原文件名}
     */
    private String generateObjectName(String fileHash, String originalFilename) {
        String date = LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyy/MM/dd"));
        String prefix = fileHash.substring(0, 8);
        return String.format("resumes/%s/%s_%s", date, prefix, originalFilename);
    }
}
```

**代码详解**：

1. **MD5 计算**：
   - 使用 `DigestUtils.md5Hex()` 计算文件哈希
   - MD5 是 32 位十六进制字符串

2. **去重检查**：
   - 先查 Redis（快）
   - 再查数据库（兜底）
   - 查到后回填 Redis（下次更快）

3. **文件路径生成**：
   - 按日期分目录：`resumes/2026/02/19/`
   - 加 MD5 前缀：`a1b2c3d4_简历.pdf`
   - 避免文件名冲突

4. **任务状态存储**：
   - Redis Key：`task:resume:{taskId}`
   - TTL：24 小时
   - 状态：QUEUED → PARSING → COMPLETED / FAILED

### 5.6 创建 Controller

**文件位置**：`src/main/java/com/smartats/module/resume/controller/ResumeController.java`

```java
package com.smartats.module.resume.controller;

import com.smartats.common.result.Result;
import com.smartats.module.resume.dto.ResumeUploadResponse;
import com.smartats.module.resume.dto.TaskStatusResponse;
import com.smartats.module.resume.service.ResumeService;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.web.bind.annotation.*;
import org.springframework.web.multipart.MultipartFile;

@Slf4j
@RestController
@RequestMapping("/api/v1/resumes")
@RequiredArgsConstructor
public class ResumeController {

    private final ResumeService resumeService;

    /**
     * 上传简历
     */
    @PostMapping("/upload")
    public Result<ResumeUploadResponse> uploadResume(
            @RequestParam("file") MultipartFile file,
            @RequestHeader("X-User-Id") Long userId  // 从 JWT 中获取，这里简化处理
    ) {
        log.info("收到简历上传请求: fileName={}, size={}", file.getOriginalFilename(), file.getSize());

        ResumeUploadResponse response = resumeService.uploadResume(file, userId);

        return Result.success(response);
    }

    /**
     * 查询任务状态
     */
    @GetMapping("/tasks/{taskId}")
    public Result<TaskStatusResponse> getTaskStatus(@PathVariable String taskId) {
        TaskStatusResponse response = resumeService.getTaskStatus(taskId);
        return Result.success(response);
    }
}
```

**注意**：
- `@RequestHeader("X-User-Id")`：实际应该从 JWT Token 中解析用户ID
- 这里为了演示简化了，后续实现 JWT 过滤器后需要修改

### 5.7 配置 Spring Security（上传接口需要认证）

**重要说明**：
- 本项目 `context-path` 为 `/api/v1`（在 `application.yml` 中配置）
- 因此 `SecurityConfig` 中的路径配置**不需要**包含 `/api/v1` 前缀
- 简历上传接口需要 JWT 认证，不需要配置 `permitAll()`

**修改文件**：`src/main/java/com/smartats/config/SecurityConfig.java`

```java
// 在 authorizeHttpRequests 中添加注释说明：
// 简历上传接口：需要认证（需要 JWT Token）
// 注意：这里不需要显式配置，因为 anyRequest().authenticated() 已经覆盖
// 但为了清晰，我们可以添加注释说明

// 实际的接口完整路径是：
// POST /api/v1/resumes/upload   → 需要认证
// GET  /api/v1/resumes/tasks/{taskId} → 需要认证
```

**✅ 正确的实现**（从 SecurityContext 获取用户 ID）：

```java
@PostMapping("/upload")
public Result<ResumeUploadResponse> uploadResume(
        @RequestParam("file") MultipartFile file,
        Authentication authentication  // 从 SecurityContext 自动注入
) {
    // 从 SecurityContext 中获取 userId（JWT 过滤器已解析）
    Long userId = (Long) authentication.getPrincipal();

    // ... 业务逻辑
}
```

**❌ 错误的实现**（不要使用）：

```java
// ❌ 不要使用请求头获取用户 ID（不安全）
@RequestHeader("X-User-Id") Long userId
```

### 5.8 测试上传接口

**⚠️ 重要**：简历上传接口需要 JWT 认证，必须先登录获取 Token。

**使用 Postman 或 curl 测试**：

```bash
# 第 1 步：登录获取 Token
curl -X POST http://localhost:8080/api/v1/auth/login \
  -H "Content-Type: application/json" \
  -d '{"username":"admin","password":"password123"}'

# 响应示例：
{
  "code": 200,
  "message": "success",
  "data": {
    "accessToken": "eyJhbGciOiJIUzI1NiJ9...",
    "refreshToken": "eyJhbGciOiJIUzI1NiJ9...",
    "userId": 1
  }
}

# 第 2 步：使用 Token 上传简历
curl -X POST http://localhost:8080/api/v1/resumes/upload \
  -H "Authorization: Bearer <your-access-token>" \
  -F "file=@/path/to/your/resume.pdf"

# 预期响应
{
  "code": 200,
  "message": "success",
  "data": {
    "taskId": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
    "resumeId": 1,
    "duplicated": false,
    "message": "简历上传成功，正在解析中"
  },
  "timestamp": 1708310400000
}

# 第 3 步：查询任务状态
curl http://localhost:8080/api/v1/resumes/tasks/{taskId} \
  -H "Authorization: Bearer <your-access-token>"
  },
  "timestamp": 1708310400000
}
```

**验收标准**：
- ✅ 文件成功上传到 MinIO
- ✅ 数据库 resumes 表有记录
- ✅ Redis 有任务状态记录
- ✅ 重复上传同一文件返回"已存在"
- ✅ 上传非 PDF/Word 文件返回错误

---

## 6. 第三阶段：RabbitMQ 集成

### 6.1 理解 RabbitMQ 核心概念

**RabbitMQ 核心组件**：

| 组件 | 说明 | 类比 |
|------|------|------|
| Producer | 消息生产者 | 发件人 |
| Consumer | 消息消费者 | 收件人 |
| Exchange | 交换机 | 邮局分拣中心 |
| Queue | 队列 | 信箱 |
| Binding Key | 绑定键 | 地址 |
| Routing Key | 路由键 | 邮编 |

**消息流向**：

```
Producer → Exchange → (Routing Key) → Queue → Consumer
```

### 6.2 配置 RabbitMQ

**文件位置**：`src/main/java/com/smartats/config/RabbitMQConfig.java`

```java
package com.smartats.config;

import org.springframework.amqp.core.*;
import org.springframework.amqp.rabbit.connection.ConnectionFactory;
import org.springframework.amqp.rabbit.core.RabbitTemplate;
import org.springframework.amqp.support.converter.Jackson2JsonMessageConverter;
import org.springframework.amqp.support.converter.MessageConverter;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class RabbitMQConfig {

    // 交换机
    public static final String RESUME_EXCHANGE = "smartats.exchange";

    // 队列
    public static final String RESUME_PARSE_QUEUE = "resume.parse.queue";

    // 死信队列
    public static final String RESUME_PARSE_DLQ = "resume.parse.dlq";

    // 死信交换机
    public static final String DEAD_LETTER_EXCHANGE = "smartats.dlx";

    // 路由键
    public static final String RESUME_PARSE_ROUTING_KEY = "resume.parse";
    public static final String DEAD_LETTER_ROUTING_KEY = "resume.parse.dlq";

    /**
     * JSON 消息转换器
     */
    @Bean
    public MessageConverter jsonMessageConverter() {
        return new Jackson2JsonMessageConverter();
    }

    /**
     * 配置 RabbitTemplate
     */
    @Bean
    public RabbitTemplate rabbitTemplate(ConnectionFactory connectionFactory) {
        RabbitTemplate rabbitTemplate = new RabbitTemplate(connectionFactory);
        rabbitTemplate.setMessageConverter(jsonMessageConverter());
        return rabbitTemplate;
    }

    /**
     * 主交换机
     */
    @Bean
    public DirectExchange resumeExchange() {
        return new DirectExchange(RESUME_EXCHANGE, true, false);
    }

    /**
     * 死信交换机
     */
    @Bean
    public DirectExchange deadLetterExchange() {
        return new DirectExchange(DEAD_LETTER_EXCHANGE, true, false);
    }

    /**
     * 主队列（带死信配置）
     */
    @Bean
    public Queue resumeParseQueue() {
        return QueueBuilder.durable(RESUME_PARSE_QUEUE)
                .withArgument("x-dead-letter-exchange", DEAD_LETTER_EXCHANGE)
                .withArgument("x-dead-letter-routing-key", DEAD_LETTER_ROUTING_KEY)
                .withArgument("x-max-retries", 3)  // 最大重试次数
                .build();
    }

    /**
     * 死信队列
     */
    @Bean
    public Queue resumeParseDLQ() {
        return QueueBuilder.durable(RESUME_PARSE_DLQ).build();
    }

    /**
     * 绑定主队列到主交换机
     */
    @Bean
    public Binding resumeParseBinding() {
        return BindingBuilder
                .bind(resumeParseQueue())
                .to(resumeExchange())
                .with(RESUME_PARSE_ROUTING_KEY);
    }

    /**
     * 绑定死信队列到死信交换机
     */
    @Bean
    public Binding deadLetterBinding() {
        return BindingBuilder
                .bind(resumeParseDLQ())
                .to(deadLetterExchange())
                .with(DEAD_LETTER_ROUTING_KEY);
    }
}
```

**配置详解**：

1. **消息转换器**：
   - 使用 `Jackson2JsonMessageConverter` 自动序列化对象为 JSON

2. **死信机制**：
   - 消息重试 3 次后进入死信队列
   - 死信队列用于后续人工处理或补偿

3. **队列持久化**：
   - `durable(true)`：队列持久化，重启不丢失
   - 消息也需要持久化（发送时设置）

### 6.3 创建消息实体

**文件位置**：`src/main/java/com/smartats/module/resume/dto/ResumeParseMessage.java`

```java
package com.smartats.module.resume.dto;

import lombok.AllArgsConstructor;
import lombok.Data;
import lombok.NoArgsConstructor;

@Data
@NoArgsConstructor
@AllArgsConstructor
public class ResumeParseMessage {

    /**
     * 任务ID
     */
    private String taskId;

    /**
     * 简历ID
     */
    private Long resumeId;

    /**
     * 用户ID
     */
    private Long userId;

    /**
     * 文件哈希
     */
    private String fileHash;

    /**
     * 重试次数
     */
    private Integer retryCount = 0;
}
```

### 6.4 创建消息发布服务

**文件位置**：`src/main/java/com/smartats/infrastructure/mq/MessagePublisher.java`

```java
package com.smartats.infrastructure.mq;

import com.smartats.config.RabbitMQConfig;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.amqp.rabbit.core.RabbitTemplate;
import org.springframework.stereotype.Service;

@Slf4j
@Service
@RequiredArgsConstructor
public class MessagePublisher {

    private final RabbitTemplate rabbitTemplate;

    /**
     * 发送简历解析消息
     */
    public void sendResumeParseMessage(Object message) {
        try {
            rabbitTemplate.convertAndSend(
                    RabbitMQConfig.RESUME_EXCHANGE,
                    RabbitMQConfig.RESUME_PARSE_ROUTING_KEY,
                    message
            );

            log.info("发送简历解析消息成功: {}", message);

        } catch (Exception e) {
            log.error("发送简历解析消息失败", e);
            throw new RuntimeException("消息发送失败", e);
        }
    }
}
```

### 6.5 修改 ResumeService 发送消息

**在 `uploadResume()` 方法中，第 10 步替换为**：

```java
// 10. 发送 MQ 消息
try {
    ResumeParseMessage message = new ResumeParseMessage(
            taskId,
            resume.getId(),
            userId,
            fileHash,
            0
    );

    messagePublisher.sendResumeParseMessage(message);

    log.info("发送解析消息成功: taskId={}, resumeId={}", taskId, resume.getId());

} catch (Exception e) {
    log.error("发送解析消息失败: taskId={}", taskId, e);
    // 不抛异常，允许用户重试查询状态
}
```

**别忘了注入 `MessagePublisher`**：

```java
private final MessagePublisher messagePublisher;
```

### 6.6 测试消息发送

**启动应用并上传文件后，检查 RabbitMQ**：

```bash
# 访问 RabbitMQ 管理界面
open http://localhost:15672

# 登录：guest / guest

# 查看 Queues → resume.parse.queue
# 应该看到有 1 条消息
```

**验收标准**：
- ✅ 队列中有消息
- ✅ 消息内容正确（JSON 格式，包含 taskId、resumeId 等）

---

## 7. 第四阶段：异步解析消费者

### 7.1 创建消费者

**文件位置**：`src/main/java/com/smartats/module/resume/consumer/ResumeParseConsumer.java`

```java
package com.smartats.module.resume.consumer;

import com.rabbitmq.client.Channel;
import com.smartats.config.RabbitMQConfig;
import com.smartats.module.resume.dto.ResumeParseMessage;
import com.smartats.module.resume.dto.TaskStatusResponse;
import com.smartats.module.resume.entity.Resume;
import com.smartats.module.resume.mapper.ResumeMapper;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.amqp.rabbit.annotation.RabbitListener;
import org.springframework.amqp.support.AmqpHeaders;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.messaging.handler.annotation.Header;
import org.springframework.stereotype.Component;

import java.io.IOException;

@Slf4j
@Component
@RequiredArgsConstructor
public class ResumeParseConsumer {

    private final ResumeMapper resumeMapper;
    private final RedisTemplate<String, Object> redisTemplate;

    private static final String TASK_STATUS_KEY_PREFIX = "task:resume:";
    private static final String LOCK_KEY_PREFIX = "lock:resume:";

    /**
     * 消费简历解析消息
     */
    @RabbitListener(queues = RabbitMQConfig.RESUME_PARSE_QUEUE)
    public void consumeResumeParse(
            ResumeParseMessage message,
            Channel channel,
            @Header(AmqpHeaders.DELIVERY_TAG) long deliveryTag
    ) {
        String taskId = message.getTaskId();
        Long resumeId = message.getResumeId();
        String fileHash = message.getFileHash();

        log.info("收到简历解析消息: taskId={}, resumeId={}", taskId, resumeId);

        try {
            // 1. 幂等检查（Redis 标记）
            String idempotentKey = "idempotent:resume:" + resumeId;
            Boolean alreadyProcessed = redisTemplate.opsForValue()
                    .setIfAbsent(idempotentKey, "1", 1, java.util.concurrent.TimeUnit.HOURS);

            if (Boolean.FALSE.equals(alreadyProcessed)) {
                log.warn("简历已处理过，跳过: resumeId={}", resumeId);
                channel.basicAck(deliveryTag, false);
                return;
            }

            // 2. 获取分布式锁（防止重复解析）
            String lockKey = LOCK_KEY_PREFIX + fileHash;
            // TODO: 使用 Redisson 获取分布式锁
            // 这里简化处理，实际应该使用 Redisson

            // 3. 更新任务状态为 PROCESSING
            updateTaskStatus(taskId, "PROCESSING", 10);

            // 4. 查询简历信息
            Resume resume = resumeMapper.selectById(resumeId);
            if (resume == null) {
                log.error("简历不存在: resumeId={}", resumeId);
                updateTaskStatus(taskId, "FAILED", 0, "简历不存在");
                channel.basicAck(deliveryTag, false);
                return;
            }

            // 5. 模拟 AI 解析（TODO: 实际调用 Spring AI）
            log.info("开始解析简历: resumeId={}, fileName={}", resumeId, resume.getFileName());

            // 模拟耗时操作
            Thread.sleep(3000);

            // TODO: 实际应该调用 AI 解析并保存到 candidates 表

            // 6. 更新任务状态为 COMPLETED
            updateTaskStatus(taskId, "COMPLETED", 100);

            // 7. 更新简历状态
            resume.setStatus("COMPLETED");
            resumeMapper.updateById(resume);

            log.info("简历解析完成: taskId={}, resumeId={}", taskId, resumeId);

            // 8. 手动确认消息
            channel.basicAck(deliveryTag, false);

        } catch (InterruptedException e) {
            log.error("简历解析被中断: taskId={}", taskId, e);
            handleFailedTask(taskId, "解析被中断");
            retryOrReject(channel, deliveryTag, message);
        } catch (Exception e) {
            log.error("简历解析失败: taskId={}", taskId, e);
            handleFailedTask(taskId, "解析失败: " + e.getMessage());
            retryOrReject(channel, deliveryTag, message);
        }
    }

    /**
     * 更新任务状态
     */
    private void updateTaskStatus(String taskId, String status, int progress) {
        updateTaskStatus(taskId, status, progress, null);
    }

    private void updateTaskStatus(String taskId, String status, int progress, String errorMessage) {
        String taskKey = TASK_STATUS_KEY_PREFIX + taskId;

        TaskStatusResponse taskStatus = new TaskStatusResponse();
        taskStatus.setStatus(status);
        taskStatus.setProgress(progress);
        taskStatus.setErrorMessage(errorMessage);

        redisTemplate.opsForValue().set(taskKey, taskStatus, 24, java.util.concurrent.TimeUnit.HOURS);

        log.info("更新任务状态: taskId={}, status={}, progress={}", taskId, status, progress);
    }

    /**
     * 处理失败任务
     */
    private void handleFailedTask(String taskId, String errorMessage) {
        updateTaskStatus(taskId, "FAILED", 0, errorMessage);
    }

    /**
     * 重试或拒绝消息
     */
    private void retryOrReject(Channel channel, long deliveryTag, ResumeParseMessage message) throws IOException {
        int retryCount = message.getRetryCount() == null ? 0 : message.getRetryCount();

        if (retryCount < 3) {
            // 重试
            log.info("消息重试: retryCount={}", retryCount);
            // TODO: 重新发送到队列，增加重试次数
            channel.basicNack(deliveryTag, false, true);
        } else {
            // 拒绝，进入死信队列
            log.error("消息重试次数超限，进入死信队列: retryCount={}", retryCount);
            channel.basicNack(deliveryTag, false, false);
        }
    }
}
```

**代码详解**：

1. **幂等检查**：
   - 使用 `setIfAbsent`（SET NX）原子操作
   - 已处理过的消息直接 ACK

2. **分布式锁**：
   - 这里简化了，实际应该使用 Redisson
   - 防止同一文件被多次解析

3. **手动 ACK**：
   - `channel.basicAck(deliveryTag, false)`：确认消息
   - `channel.basicNack(deliveryTag, false, true)`：重试
   - `channel.basicNack(deliveryTag, false, false)`：拒绝，进入死信队列

4. **状态更新**：
   - PARSING → PROCESSING → COMPLETED / FAILED
   - 实时更新 Redis，供前端查询

### 7.2 配置 Spring Security（允许消费）

RabbitMQ 消费者在后台运行，不需要 HTTP 访问，无需配置 Security。

### 7.3 测试消费者

**测试步骤**：

1. 上传一份简历
2. 观察 RabbitMQ 管理界面，队列消息被消费
3. 查询任务状态接口，看到状态变化

```bash
# 上传简历
curl -X POST http://localhost:8080/api/v1/resumes/upload \
  -H "X-User-Id: 1" \
  -F "file=@resume.pdf"

# 获取 taskId，然后轮询查询
curl http://localhost:8080/api/v1/resumes/tasks/{taskId}
```

**预期状态变化**：

```
QUEUED (0%) → PROCESSING (10%) → COMPLETED (100%)
```

**验收标准**：
- ✅ 消息被消费
- ✅ 任务状态正确更新
- ✅ resumes 表状态更新为 COMPLETED
- ✅ 重复消息不会重复处理（幂等）

---

## 8. 第五阶段：任务状态跟踪

### 8.1 理解轮询机制

**前端轮询流程**：

```
1. 上传简历 → 获得 taskId
2. 每隔 2 秒调用 GET /api/v1/resumes/tasks/{taskId}
3. 检查 status：
   - QUEUED / PROCESSING → 继续轮询
   - COMPLETED → 停止轮询，显示结果
   - FAILED → 停止轮询，显示错误
4. 最多轮询 5 分钟（超时）
```

### 8.2 优化轮询接口

**文件位置**：`src/main/java/com/smartats/module/resume/service/ResumeService.java`

**修改 `getTaskStatus()` 方法**：

```java
/**
 * 查询任务状态（优化版）
 */
public TaskStatusResponse getTaskStatus(String taskId) {
    String taskKey = TASK_STATUS_KEY_PREFIX + taskId;

    // 1. 先查 Redis
    TaskStatusResponse status = (TaskStatusResponse) redisTemplate.opsForValue().get(taskKey);

    if (status != null) {
        // 如果是 COMPLETED，补充更多信息
        if ("COMPLETED".equals(status.getStatus())) {
            // 查询候选人信息
            // TODO: 关联 candidates 表
        }
        return status;
    }

    // 2. Redis 没有，可能已过期，查数据库兜底
    // 从 taskId 解析出 resumeId（假设 taskId = resumeId）
    // 实际项目中应该存储 taskId → resumeId 的映射

    return new TaskStatusResponse("NOT_FOUND", null, null, "任务不存在或已过期", 0);
}
```

### 8.3 添加 Webhook 支持（可选）

**文件位置**：`src/main/java/com/smartats/module/resume/dto/ResumeUploadRequest.java`

```java
@Data
public class ResumeUploadRequest {

    private MultipartFile file;

    /**
     * Webhook URL（可选，解析完成后回调）
     */
    private String webhookUrl;
}
```

**消费者中添加 Webhook 调用**：

```java
// 解析完成后
if ("COMPLETED".equals(status)) {
    if (webhookUrl != null) {
        callWebhook(webhookUrl, taskStatus);
    }
}
```

**Webhook 调用示例**：

```java
private void callWebhook(String webhookUrl, TaskStatusResponse status) {
    try {
        RestTemplate restTemplate = new RestTemplate();
        restTemplate.postForEntity(webhookUrl, status, Void.class);
        log.info("Webhook 调用成功: url={}", webhookUrl);
    } catch (Exception e) {
        log.error("Webhook 调用失败: url={}", webhookUrl, e);
    }
}
```

---

## 9. 完整代码示例

### 9.1 目录结构

```
src/main/java/com/smartats/
├── config/
│   ├── MinioConfig.java
│   └── RabbitMQConfig.java
├── common/
│   ├── result/
│   │   └── Result.java
│   └── exception/
│       └── GlobalExceptionHandler.java
├── module/
│   └── resume/
│       ├── controller/
│       │   └── ResumeController.java
│       ├── service/
│       │   └── ResumeService.java
│       ├── mapper/
│       │   └── ResumeMapper.java
│       ├── entity/
│       │   └── Resume.java
│       ├── dto/
│       │   ├── ResumeUploadResponse.java
│       │   ├── TaskStatusResponse.java
│       │   └── ResumeParseMessage.java
│       └── consumer/
│           └── ResumeParseConsumer.java
└── infrastructure/
    ├── storage/
    │   ├── FileStorageService.java
    │   └── MinioFileStorageService.java
    └── mq/
        └── MessagePublisher.java
```

### 9.2 配置文件完整示例

**文件位置**：`src/main/resources/application.yml`

```yaml
# 应用配置
server:
  port: 8080
  servlet:
    context-path: /api/v1  # 全局路径前缀

spring:
  application:
    name: smartats

  # 数据源配置
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://localhost:3307/smartats?useSSL=false&serverTimezone=Asia/Shanghai
    username: smartats
    password: smartats123

  # Redis 配置
  data:
    redis:
      host: localhost
      port: 6379
      password: redis123
      database: 0

  # RabbitMQ 配置
  rabbitmq:
    host: localhost
    port: 5672
    username: admin
    password: admin123
    virtual-host: smartats
    listener:
      simple:
        acknowledge-mode: manual
        prefetch: 1

  # 文件上传配置
  servlet:
    multipart:
      enabled: true
      max-file-size: 10MB
      max-request-size: 50MB

# MinIO 配置
minio:
  endpoint: http://localhost:9000
  access-key: admin
  secret-key: admin123456
  bucket-name: smartats-resumes
  connect-timeout: 10000
  write-timeout: 60000
  read-timeout: 10000

# MyBatis-Plus 配置
mybatis-plus:
  configuration:
    map-underscore-to-camel-case: true
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
  global-config:
    db-config:
      id-type: auto

# 日志配置
logging:
  level:
    com.smartats: DEBUG
  pattern:
    console: '%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n'
```

**⚠️ 重要说明**：
- 数据库端口：`3307`（不是默认的 3306）
- MinIO 凭证：`admin/admin123456`（不是 minioadmin）
- RabbitMQ 凭证：`admin/admin123`（不是 guest）
- RabbitMQ virtual-host：`smartats`（不是 /）

---

## 10. 测试验收标准

### 10.1 功能测试清单

#### 基础功能

- [x] 上传 PDF 文件成功
- [x] 上传 Word 文件成功
- [ ] 上传其他格式文件被拒绝
- [ ] 上传超大文件（>10MB）被拒绝
- [ ] 上传空文件被拒绝

#### 去重功能

- [ ] 重复上传同一文件返回"已存在"
- [ ] 去重后返回正确的 resumeId
- [ ] Redis 去重标记正确设置（7天TTL）

#### 文件存储

- [ ] 文件成功上传到 MinIO
- [ ] 文件路径格式正确（resumes/2026/02/19/...）
- [ ] 文件可通过 URL 访问

#### 数据库

- [ ] resumes 表记录正确
- [ ] file_hash 正确保存
- [ ] 初始状态为 PARSING

#### 异步处理

- [ ] MQ 消息发送成功
- [ ] 消息被消费
- [ ] 任务状态正确更新（QUEUED → PROCESSING → COMPLETED）
- [ ] resumes 表状态更新为 COMPLETED

#### 任务查询

- [ ] 能查询到任务状态
- [ ] 状态变化实时反映
- [ ] 过期任务返回 NOT_FOUND

### 10.2 性能测试

**使用 Apache Bench (ab) 压测**：

```bash
# 安装 ab
brew install ab

# 并发上传 10 个文件
ab -n 10 -c 10 -p testfile.pdf -T "multipart/form-data; boundary=----WebKitFormBoundary" \
  http://localhost:8080/api/v1/resumes/upload
```

**性能指标**：

| 指标 | 目标 | 实际 |
|------|------|------|
| 平均响应时间 | < 500ms | _____ |
| 99% 响应时间 | < 1000ms | _____ |
| 吞吐量 | > 20 req/s | _____ |

### 10.3 异常测试

- [ ] MinIO 服务停止时上传失败
- [ ] RabbitMQ 服务停止时消息重试
- [ ] Redis 服务停止时降级到数据库查询
- [ ] 数据库连接失败时返回错误

---

## 11. 常见问题排查

### 11.1 文件上传失败

**问题**：上传接口返回 500 错误

**排查步骤**：

1. 检查 MinIO 是否运行
```bash
docker ps | grep minio
curl http://localhost:9000/minio/health/live
```

2. 检查 Bucket 是否存在
```bash
# 访问控制台
open http://localhost:9001
```

3. 检查文件大小限制
```yaml
# application.yml
spring:
  servlet:
    multipart:
      max-file-size: 10MB
```

4. 查看应用日志
```bash
tail -f logs/smartats.log | grep ERROR
```

### 11.2 消息未被消费

**问题**：队列中有消息，但消费者不处理

**排查步骤**：

1. 检查消费者是否启动
```bash
# 查看日志
tail -f logs/smartats.log | grep "收到简历解析消息"
```

2. 检查 RabbitMQ 连接
```bash
# 访问管理界面
open http://localhost:15672

# 查看 Connections
```

3. 检查队列绑定
```bash
# 查看 Queues → resume.parse.queue → Bindings
```

4. 手动 ACK 配置
```yaml
spring:
  rabbitmq:
    listener:
      simple:
        acknowledge-mode: manual
```

### 11.3 任务状态不更新

**问题**：查询任务状态一直是 QUEUED

**排查步骤**：

1. 检查 Redis 是否运行
```bash
redis-cli ping
```

2. 检查 Redis Key 是否存在
```bash
redis-cli
> KEYS task:resume:*
> GET task:resume:{taskId}
```

3. 检查消费者是否报错
```bash
tail -f logs/smartats.log | grep "简历解析"
```

### 11.4 去重不生效

**问题**：重复上传同一文件没有返回"已存在"

**排查步骤**：

1. 检查 MD5 计算
```java
// 添加日志
log.info("文件MD5: {}", fileHash);
```

2. 检查 Redis 去重标记
```bash
redis-cli
> GET dedup:resume:{md5}
```

3. 检查数据库 file_hash
```sql
SELECT id, file_hash FROM resumes WHERE file_hash = 'your_md5';
```

### 11.5 MinIO 文件访问 403

**问题**：上传成功，但访问文件 URL 返回 403

**原因**：Bucket 不是公共访问

**解决方案**：

方案 1：设置 Bucket 为 Public（开发环境）
```bash
# 使用 MinIO 客户端
mc policy set public myminio/smartats-resumes
```

方案 2：使用预签名 URL（推荐生产环境）
```java
String url = fileStorageService.getPresignedUrl(objectName, 3600);
```

---

## 12. 下一步优化方向

### 12.1 已实现的功能

- ✅ MinIO 文件存储
- ✅ 文件上传接口
- ✅ MD5 去重
- ✅ RabbitMQ 异步处理
- ✅ 任务状态跟踪
- ✅ 基础消费者

### 12.2 待优化的点

- [ ] **分布式锁**：使用 Redisson 替代简化实现
- [ ] **AI 解析**：集成 Spring AI 进行简历提取
- [ ] **候选人存储**：解析完成后保存到 candidates 表
- [ ] **向量存储**：生成 embedding 并存入向量库
- [ ] **重试机制**：完善消息重试逻辑
- [ ] **死信处理**：定时扫描死信队列并补偿
- [ ] **监控告警**：集成 Prometheus + Grafana
- [ ] **限流**：防止用户频繁上传

### 12.3 扩展功能

- [ ] **批量上传**：支持一次上传多个文件
- [ ] **文件预览**：在线预览 PDF/Word
- [ ] **文件加密**：敏感文件加密存储
- [ ] **CDN 加速**：使用 CDN 加速文件访问
- [ ] **Webhook 通知**：解析完成后主动推送

---

## 13. 学习检查点

完成本模块后，你应该掌握：

### 技术知识点

- [ ] MinIO 对象存储的使用
- [ ] 文件上传的最佳实践
- [ ] MD5 哈希用于去重
- [ ] RabbitMQ 基本概念和使用
- [ ] 死信队列机制
- [ ] 消息幂等性处理
- [ ] 异步任务状态跟踪

### 设计模式

- [ ] 面向接口编程（FileStorageService）
- [ ] 生产者-消费者模式
- [ ] 异步处理模式
- [ ] 幂等性设计

### 实战能力

- [ ] 独立搭建 MinIO 环境
- [ ] 独立配置 RabbitMQ
- [ ] 独立实现文件上传功能
- [ ] 独立排查消息队列问题

---

## 14. 参考资源

### 官方文档

- [MinIO Java SDK](https://min.io/docs/minio/linux/developers/java/minio-java.html)
- [Spring AMQP](https://docs.spring.io/spring-amqp/reference/)
- [RabbitMQ 官方文档](https://www.rabbitmq.com/docs)

### 推荐阅读

- [RabbitMQ 实战指南](https://book.douban.com/subject/27017918/)
- [分布式系统模式](https://book.douban.com/subject/26717479/)

---

## 15. 总结

本模块涵盖了简历上传的核心流程：

1. **MinIO 配置与使用**：对象存储的最佳实践
2. **文件上传接口**：校验、去重、存储一条龙
3. **RabbitMQ 集成**：异步解耦提升性能
4. **消息消费者**：幂等、重试、死信机制
5. **任务状态跟踪**：Redis + 轮询实现实时反馈

按照本文档的步骤，你可以独立完成一个生产级别的文件上传模块。

**记住**：
- 先让流程跑通，再优化细节
- 异步处理不要阻塞主流程
- 一定要做好幂等和重试
- 监控和日志必不可少

祝你学习顺利！🎉
